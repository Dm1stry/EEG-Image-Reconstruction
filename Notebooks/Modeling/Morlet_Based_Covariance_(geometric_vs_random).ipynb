{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3a59e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "os.chdir('../..')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a4807-a359-4f07-ba32-d4dbb7b52492",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "125d3f8d-dd26-4af3-8a28-68c9948bcc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing exp_paths: 100%|██████████| 31/31 [00:00<00:00, 44.79it/s]\n",
      "Loading .fif files: 100%|██████████| 651/651 [00:29<00:00, 21.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Firstly import the class of dataset\n",
    "from Scripts.Data_Loader import EIRDataset\n",
    "\n",
    "EIR_Dataset = EIRDataset('./Generated/Data_Train/', task_type='all', n_jobs=72) # task type can be `geometric` or `random` or `all`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e11b8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "# Это потомучто финальные \n",
    "min_len = 3946 \n",
    "\n",
    "def resample_df(EIR_Dataset, freq: int):\n",
    "    for i in range(len(EIR_Dataset)): \n",
    "        eeg_sample, eye_sample, metadata, label, img = EIR_Dataset[i]\n",
    "\n",
    "        eeg_sample.resample(freq)\n",
    "\n",
    "        # Обрезаем только нужное количество сэмплов\n",
    "        data = eeg_sample.get_data()[:, :min_len]\n",
    "        new_raw = mne.io.RawArray(data, eeg_sample.info, verbose=False)\n",
    "\n",
    "        # Сохраняем обратно изменённый элемент\n",
    "        EIR_Dataset[i] = (new_raw, eye_sample, metadata, label, img)\n",
    "\n",
    "resample_df(EIR_Dataset, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18d0753-be99-4c7a-bea0-bdc527483a33",
   "metadata": {},
   "source": [
    "# Form X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "799731dc-1172-40fe-95ae-c371f94bf54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts import Selectors_From_Dataset as sel\n",
    "import numpy as np\n",
    "X, img, y = sel.get_sample(EIR_Dataset)\n",
    "\n",
    "# Here random patterns are set to 1\n",
    "y = np.where(y == -1, 1, 0)\n",
    "\n",
    "# Here geometric patterns are set to 1\n",
    "# y = np.where(y != -1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b882f8c7-dbdb-43cc-8b8e-b2328193e610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((651, 63, 3946), (651,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77973d49-7bb1-40a3-8d6d-4a9adacb6247",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc42ebfe-712c-426a-8e8b-b7d19671214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from pyriemann.estimation import Covariances\n",
    "from typing import Union\n",
    "\n",
    "n_components = 4\n",
    "class ModelCovariance:\n",
    "    class ParallelCovariances(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, n_filters, covariance_type: Union[list, type] = Covariances):\n",
    "            self.covariance_type = covariance_type\n",
    "            self.n_filters = n_filters\n",
    "            self.cov = []\n",
    "            self.cov_pipeline = []\n",
    "\n",
    "            for i, cov_type in enumerate(covariance_type):\n",
    "                if cov_type == XdawnCovariances:\n",
    "                    self.cov.append(cov_type(nfilter = self.n_filters[i], estimator = 'lwf', xdawn_estimator='lwf'))\n",
    "                else: self.cov.append(cov_type(estimator = 'lwf'))\n",
    "        def fit(self, X, y):\n",
    "            self.cov_pipeline = []\n",
    "            for i in range(len(X)):\n",
    "                self.cov_pipeline.append(Pipeline([\n",
    "                ('covariance', self.cov[i]),\n",
    "                ('tangent', TangentSpace())]))\n",
    "                self.cov_pipeline[i].fit(X[i], y)\n",
    "            return self\n",
    "        \n",
    "        def transform(self, X):\n",
    "            ret = []\n",
    "            for i in range(len(X)):\n",
    "                ret.append(self.cov_pipeline[i].transform(X[i]))\n",
    "            combined = np.concatenate(ret, axis=1)\n",
    "            return combined\n",
    "\n",
    "        \n",
    "    def __init__(self, feature_groups: int = 3, n_filters: Union[list, int, None] = 4, covariances: Union[list, type] = XdawnCovariances,\n",
    "                  Classifier: Union[list, BaseEstimator] = LogisticRegression(C=3, class_weight='balanced', max_iter = 300)):\n",
    "        self.feature_groups = feature_groups\n",
    "        self.covariances = covariances\n",
    "        self.n_filters = n_filters\n",
    "        if feature_groups == 1: # Предполагается что в этом случае нигде не используется list для передачи параметров\n",
    "            cov = covariances(estimator='lwf')\n",
    "            if covariances == XdawnCovariances:\n",
    "                cov = covariances(n_filters, estimator='lwf', xdawn_estimator='lwf')\n",
    "            self.pipeline = Pipeline([\n",
    "                ('cov', cov),\n",
    "                ('tang', TangentSpace()),\n",
    "                ('clf', Classifier)])\n",
    "        else: # Если используем листы для передачи параметров - следим чтобы длина совпадала с feature_groups\n",
    "            if isinstance(n_filters, int):\n",
    "                self.n_filters = [n_filters] * feature_groups\n",
    "            if isinstance(covariances, type):\n",
    "                self.covariances = [covariances] * feature_groups\n",
    "            self.pipeline = (Pipeline([\n",
    "                ('cov', self.ParallelCovariances(self.n_filters, self.covariances)),\n",
    "                ('clf', Classifier)]))\n",
    "    def get_pipeline(self):\n",
    "        return self.pipeline\n",
    "    def fit(self, X, y):\n",
    "        self.pipeline.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.pipeline.predict(X)\n",
    "    \n",
    "    def evaluate(self, X, true_y, metric: Union[str, list] = 'accuracy'):\n",
    "        preds = self.pipeline.predict(X)\n",
    "        if isinstance(metric, str):\n",
    "            if metric == 'accuracy':\n",
    "                return metrics.accuracy_score(true_y, preds)\n",
    "            elif metric == 'precision':\n",
    "                return metrics.precision_score(true_y, preds, average='weighted')\n",
    "            elif metric == 'recall':\n",
    "                return metrics.recall_score(true_y, preds, average='weighted')\n",
    "            elif metric == 'f1':\n",
    "                return metrics.f1_score(true_y, preds, average='weighted')\n",
    "            elif metric == 'roc_auc':\n",
    "                return metrics.roc_auc_score(true_y, preds)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown metric: {metric}\")\n",
    "        \n",
    "        elif isinstance(metric, list):\n",
    "            results = {}\n",
    "            for m in metric:\n",
    "                if m == 'accuracy':\n",
    "                    results[m] = metrics.accuracy_score(true_y, preds)\n",
    "                elif m == 'precision':\n",
    "                    results[m] = metrics.precision_score(true_y, preds, average='weighted')\n",
    "                elif m == 'recall':\n",
    "                    results[m] = metrics.recall_score(true_y, preds, average='weighted')\n",
    "                elif m == 'f1':\n",
    "                    results[m] = metrics.f1_score(true_y, preds, average='weighted')\n",
    "                elif m == 'roc_auc':\n",
    "                    results[m] = metrics.roc_auc_score(true_y, preds)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown metric: {m}\")\n",
    "            return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a0e634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- For Test_Size 0.1 ------ Random Guess: 0.333 ----------\n",
      "{'accuracy': 0.803030303030303, 'f1': 0.7811447811447811}\n",
      "---------- For Test_Size 0.15 ------ Random Guess: 0.337 ----------\n",
      "{'accuracy': 0.7653061224489796, 'f1': 0.7471908145762594}\n",
      "---------- For Test_Size 0.2 ------ Random Guess: 0.336 ----------\n",
      "{'accuracy': 0.7633587786259542, 'f1': 0.7424258839215443}\n",
      "---------- For Test_Size 0.25 ------ Random Guess: 0.331 ----------\n",
      "{'accuracy': 0.7668711656441718, 'f1': 0.7501745818238059}\n",
      "---------- For Test_Size 0.3 ------ Random Guess: 0.332 ----------\n",
      "{'accuracy': 0.7806122448979592, 'f1': 0.7658856754703848}\n",
      "---------- For Test_Size 0.35 ------ Random Guess: 0.333 ----------\n",
      "{'accuracy': 0.7719298245614035, 'f1': 0.7573833573833573}\n",
      "---------- For Test_Size 0.4 ------ Random Guess: 0.333 ----------\n",
      "{'accuracy': 0.7394636015325671, 'f1': 0.719421590625779}\n",
      "---------- For Test_Size 0.45 ------ Random Guess: 0.334 ----------\n",
      "{'accuracy': 0.7542662116040956, 'f1': 0.7295500516642139}\n",
      "---------- For Test_Size 0.5 ------ Random Guess: 0.334 ----------\n",
      "{'accuracy': 0.7515337423312883, 'f1': 0.7251487933338753}\n",
      "---------- For Test_Size 0.55 ------ Random Guess: 0.334 ----------\n",
      "{'accuracy': 0.7604456824512534, 'f1': 0.7324777407998591}\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "test_example = ModelCovariance(feature_groups=1, n_filters=80,\n",
    "                               covariances=XdawnCovariances, \n",
    "                               Classifier=LogisticRegression(C=1, class_weight='balanced', max_iter = 1000))\n",
    "\n",
    "# test_example2 = ModelCovariance(feature_groups=3, n_filters=4, \n",
    "#                                 covariances=[XdawnCovariances, Covariances, Covariances], \n",
    "#                                 Classifier=LogisticRegression(C=3, class_weight='balanced', max_iter = 300))\n",
    "\n",
    "# test_example3 = ModelCovariance(feature_groups=2, n_filters=4, \n",
    "#                                 covariances=[XdawnCovariances, Covariances], \n",
    "#                                 Classifier=LogisticRegression(C=3, class_weight='balanced', max_iter = 300))\n",
    "\n",
    "# test_example4 = ModelCovariance(feature_groups=2, n_filters=4, \n",
    "#                                 covariances=[XdawnCovariances, Covariances], \n",
    "#                                 Classifier=LogisticRegression(C=3, class_weight='balanced', max_iter = 300))\n",
    "\n",
    "# test_example5 = ModelCovariance(feature_groups=2, n_filters=4, \n",
    "#                                 covariances=[Covariances, Covariances], \n",
    "#                                 Classifier=LogisticRegression(C=3, class_weight='balanced', max_iter = 300))\n",
    "\n",
    "test_sizes = [0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55]\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    \n",
    "    # X, img, y = sel.get_sample(EIR_Dataset)\n",
    "    # subjects_cluster3 = [7, 7, 9, 9, 14]\n",
    "    # trial_cluster3 = [2, 1, 2, 1, 1]\n",
    "    # subjects_cluster4 = [5, 5, 3, 3, 2, 2, 10, 10, 12, 12, 16, 16, 11, 11, 13, 13]\n",
    "    # trial_cluster4 = [2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1]\n",
    "    # X, img, y = sel.get_sample_choosen_trial(EIR_Dataset, subjects_cluster4 + subjects_cluster3, trial_cluster4 + trial_cluster3)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=42)\n",
    "\n",
    "    # Smote только на тренировочном сете\n",
    "    smote = SMOTE(random_state=42)\n",
    "    _, n_channels, n_timepoints = X_train.shape\n",
    "    X_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_resampled_flat, Y_train = smote.fit_resample(X_flat, Y_train)\n",
    "    X_train = X_resampled_flat.reshape(-1, n_channels, n_timepoints) \n",
    "    \n",
    "    test_example.fit(X_train, Y_train)\n",
    "    print(f\"---------- For Test_Size {test_size} ------ Random Guess: {Y_test.sum()/len(Y_test):.3f} ----------\")\n",
    "    print(test_example.evaluate(X_test, Y_test, ['accuracy', 'f1']))\n",
    "\n",
    "# test_example2.fit([X_train, power_wav_train, phase_wav_train], Y_train)\n",
    "# print(test_example2.evaluate([X_test, power_wav_test, phase_wav_test], Y_test, ['accuracy', 'f1']))\n",
    "\n",
    "# test_example3.fit([X_train, power_wav_train], Y_train)\n",
    "# print(test_example3.evaluate([X_test, power_wav_test], Y_test, ['accuracy', 'f1']))\n",
    "\n",
    "# test_example4.fit([X_train, phase_wav_train], Y_train)\n",
    "# print(test_example4.evaluate([X_test, phase_wav_test], Y_test, ['accuracy', 'f1']))\n",
    "\n",
    "# test_example5.fit([power_wav_train, phase_wav_train], Y_train)\n",
    "# print(test_example5.evaluate([power_wav_test, phase_wav_test], Y_test, ['accuracy', 'f1']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
