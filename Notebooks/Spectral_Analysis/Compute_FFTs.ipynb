{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64dfeff4-0efd-4b85-ba21-e655f2743d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "import mne\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap\n",
    "from sklearn.cluster import DBSCAN\n",
    "from multiprocessing import Pool\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "mne.set_log_level('ERROR')\n",
    "\n",
    "os.chdir('../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e2b67-5145-4e62-bd00-449ff3b2c04c",
   "metadata": {},
   "source": [
    "# Load All The Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f1b2b2-2986-41c3-aab3-931e6c7a9d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 31 подходящих директорий\n"
     ]
    }
   ],
   "source": [
    "def collect_valid_paths():\n",
    "    root_dir = \"Generated/Data\"\n",
    "    s_dir_pattern = re.compile(r\"^S_\\d+$\")\n",
    "    trial_dir_pattern = re.compile(r\"^Trial_\\d+$\")\n",
    "    valid_dirs = []\n",
    "    for s_dir in os.listdir(root_dir):\n",
    "        s_path = os.path.join(root_dir, s_dir)\n",
    "        if os.path.isdir(s_path) and s_dir_pattern.match(s_dir):\n",
    "            for trial_dir in os.listdir(s_path):\n",
    "                trial_path = os.path.join(s_path, trial_dir)\n",
    "                if os.path.isdir(trial_path) and trial_dir_pattern.match(trial_dir):\n",
    "                    if any(os.path.isfile(os.path.join(trial_path, f)) for f in os.listdir(trial_path)):\n",
    "                        valid_dirs.append(trial_path)\n",
    "    return valid_dirs\n",
    "\n",
    "all_paths = collect_valid_paths()\n",
    "\n",
    "print(f\"Найдено {len(all_paths)} подходящих директорий\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d9b3a6d-33ef-4f84-baec-ecc234bc019c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:48<00:00,  3.51s/it]\n"
     ]
    }
   ],
   "source": [
    "def load_eeg(path):\n",
    "    eeg_clean_path = os.path.join(path, \"EEG_clean.fif\")\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"mne\")\n",
    "        clean_eeg = mne.io.read_raw_fif(eeg_clean_path, preload=True, verbose=False)\n",
    "    \n",
    "    clean_eeg.pick_types(eeg=True, verbose=False)\n",
    "\n",
    "    # Извлечем S_13 и Trial_2 из пути\n",
    "    parts = path.strip(os.sep).split(os.sep)\n",
    "    subj = parts[-2]\n",
    "    trial = parts[-1]\n",
    "\n",
    "    subj_id = int(subj.split('_')[-1])\n",
    "    trial_id = int(trial.split('_')[-1])\n",
    "\n",
    "    \n",
    "    key = f\"S{subj_id}_T{trial_id}\"\n",
    "\n",
    "    return key, [clean_eeg, subj_id, trial_id]\n",
    "        \n",
    "\n",
    "# Параллельная загрузка\n",
    "with Pool(processes=72)  as pool:\n",
    "    results = list(tqdm(pool.imap(load_eeg, all_paths), total=len(all_paths)))\n",
    "\n",
    "# Собрать словарь, исключив ошибки\n",
    "data_tuple = {k: v for k, v in results if k is not None}\n",
    "\n",
    "eeg, subj, trial = data_tuple['S6_T1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196c685-0a1e-427a-b6fe-137307e83bb5",
   "metadata": {},
   "source": [
    "# Average FFT Spectrums on All Experiment (PSD)\n",
    "As a result, produces:\n",
    "* `psds_array` - list of psds morlet wavelet spectras\n",
    "* `metadata`   - list of [`sub_id`, `trial_id`, `gender`, `handiness`, `age`, ...] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0623d7-f681-4b46-80d6-89e0f2980955",
   "metadata": {},
   "source": [
    "### Exclude 300 sec and 30 sec rest blocks\n",
    "All subjects have the same structure of the experiment, so we will get timings of these blocks from S1_T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fdb9f9-bb6f-41aa-932d-ec1d55d559fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = f\"./Generated/Data/S_1/Trial_1/Experiment.json\"\n",
    "\n",
    "# Load experiment sequence\n",
    "with open(experiment_path,'r') as f:\n",
    "    experiment_seq = json.load(f)\n",
    "    \n",
    "clean_blocks = [\n",
    "    (block_data['timestamp'], block_data['content']['duration'])\n",
    "    for block_data in experiment_seq.values()\n",
    "    if not (block_data['type'] == 'rest' and (block_data['content']['duration'] == 300 or block_data['content']['duration'] == 30))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4a56d79-3e63-4aa6-813d-a7cf46191e18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG for S4_T2 is cropped for 918080 samples.\n",
      "EEG for S4_T1 is cropped for 918080 samples.\n",
      "EEG for S14_T1 is cropped for 917995 samples.\n",
      "EEG for S15_T2 is cropped for 918080 samples.\n",
      "EEG for S15_T1 is cropped for 918080 samples.\n",
      "EEG for S1_T2 is cropped for 918080 samples.\n",
      "EEG for S1_T1 is cropped for 918080 samples.\n",
      "EEG for S5_T2 is cropped for 918080 samples.\n",
      "EEG for S5_T1 is cropped for 918080 samples.\n",
      "EEG for S3_T2 is cropped for 918080 samples.\n",
      "EEG for S3_T1 is cropped for 918080 samples.\n",
      "EEG for S2_T2 is cropped for 918080 samples.\n",
      "EEG for S2_T1 is cropped for 918080 samples.\n",
      "EEG for S7_T2 is cropped for 918080 samples.\n",
      "EEG for S7_T1 is cropped for 918080 samples.\n",
      "EEG for S10_T2 is cropped for 918080 samples.\n",
      "EEG for S10_T1 is cropped for 918080 samples.\n",
      "EEG for S8_T2 is cropped for 918080 samples.\n",
      "EEG for S8_T1 is cropped for 918080 samples.\n",
      "EEG for S12_T2 is cropped for 918080 samples.\n",
      "EEG for S12_T1 is cropped for 918080 samples.\n",
      "EEG for S16_T2 is cropped for 918080 samples.\n",
      "EEG for S11_T2 is cropped for 918080 samples.\n",
      "EEG for S16_T1 is cropped for 918080 samples.\n",
      "EEG for S11_T1 is cropped for 918080 samples.\n",
      "EEG for S9_T2 is cropped for 918080 samples.\n",
      "EEG for S13_T2 is cropped for 918080 samples.\n",
      "EEG for S9_T1 is cropped for 918080 samples.\n",
      "EEG for S13_T1 is cropped for 918080 samples.\n",
      "EEG for S6_T2 is cropped for 918080 samples.\n",
      "EEG for S6_T1 is cropped for 918080 samples.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "\n",
    "# Функция для обработки одного элемента\n",
    "def process_key(key_data, clean_blocks):\n",
    "    key, (eeg, subj, trial) = key_data\n",
    "\n",
    "    # Собираем отрезки с execution\n",
    "    epochs = []\n",
    "    for start_time, duration in clean_blocks:\n",
    "        start_sample = int(start_time)\n",
    "        stop_sample = min(int((start_time + duration)), len(eeg) / 1000.0 - 0.001)\n",
    "        segment = eeg.copy().crop(tmin=start_sample, tmax=stop_sample)\n",
    "        epochs.append(segment)\n",
    "\n",
    "    # Объединяем execution-сегменты\n",
    "    cropped_eeg = mne.concatenate_raws(epochs)\n",
    "    print(f\"EEG for {key} is cropped for {len(cropped_eeg)} samples.\")\n",
    "\n",
    "    return key, (cropped_eeg, subj, trial)\n",
    "\n",
    "# Мультипроцессинг\n",
    "with Pool(processes=72) as pool:\n",
    "    func = partial(process_key, clean_blocks=clean_blocks)\n",
    "    data_tuple = dict(pool.map(func, data_tuple.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efd28e2-4b67-4d38-a153-562657a82d3c",
   "metadata": {},
   "source": [
    "### Get the subjects info\n",
    "Will be usefull to pack ones for spectrums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6352ccde-e0ce-4355-b4c7-c7bd33e29c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Surname</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Handiness</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Софья</td>\n",
       "      <td>Гамершмидт</td>\n",
       "      <td>f</td>\n",
       "      <td>r</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Сергей</td>\n",
       "      <td>Пешков</td>\n",
       "      <td>m</td>\n",
       "      <td>r</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Рувшан</td>\n",
       "      <td>Давлитшин</td>\n",
       "      <td>m</td>\n",
       "      <td>r</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Мухаббат</td>\n",
       "      <td>Давлатова</td>\n",
       "      <td>f</td>\n",
       "      <td>r</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Камиль</td>\n",
       "      <td>Фоатов</td>\n",
       "      <td>m</td>\n",
       "      <td>r</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Алия</td>\n",
       "      <td>Хадеева</td>\n",
       "      <td>f</td>\n",
       "      <td>r</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Алёна</td>\n",
       "      <td>Петренко</td>\n",
       "      <td>f</td>\n",
       "      <td>r</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Умар</td>\n",
       "      <td>Магомедов</td>\n",
       "      <td>m</td>\n",
       "      <td>r</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Мария</td>\n",
       "      <td>Мельникова</td>\n",
       "      <td>f</td>\n",
       "      <td>r</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Нурсултан</td>\n",
       "      <td>Абдулаев</td>\n",
       "      <td>m</td>\n",
       "      <td>r</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Никита</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>r</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Анатолий</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>r</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Иван</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Анна</td>\n",
       "      <td>Тихонова</td>\n",
       "      <td>f</td>\n",
       "      <td>r</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Татьяна</td>\n",
       "      <td>Ившина</td>\n",
       "      <td>f</td>\n",
       "      <td>r</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ева</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>r</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name     Surname Gender Handiness  Age\n",
       "Subject_id                                             \n",
       "1               Софья  Гамершмидт      f         r   21\n",
       "2              Сергей      Пешков      m         r   19\n",
       "3              Рувшан   Давлитшин      m         r   18\n",
       "4            Мухаббат   Давлатова      f         r   30\n",
       "5              Камиль      Фоатов      m         r    0\n",
       "6                Алия     Хадеева      f         r   18\n",
       "7               Алёна    Петренко      f         r   19\n",
       "8                Умар   Магомедов      m         r   18\n",
       "9               Мария  Мельникова      f         r   31\n",
       "10          Нурсултан    Абдулаев      m         r   20\n",
       "11             Никита         NaN      m         r   18\n",
       "12           Анатолий         NaN      m         r   20\n",
       "13               Иван         NaN      m       NaN    0\n",
       "14               Анна    Тихонова      f         r   18\n",
       "15            Татьяна      Ившина      f         r   23\n",
       "16                Ева         NaN      f         r   18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# --- 1) Читаем Excel, пропуская первую строку «слитного» заголовка ---\n",
    "file_path = './Supplementary/Experiment_Metadata.xlsx'\n",
    "df_raw = pd.read_excel(file_path, header=1)\n",
    "\n",
    "# --- 2) Переименовываем нужные колонки ---\n",
    "df_raw = df_raw.rename(columns={\n",
    "    'Subject ID'         : 'Subject_id',\n",
    "    'Имя'                : 'Name',\n",
    "    'Фамилия'            : 'Surname',\n",
    "    'Дата Рождения'      : 'Birthdate',\n",
    "    'Пол'                : 'Gender',\n",
    "    'Правша / Левша'     : 'Handiness',\n",
    "})\n",
    "\n",
    "# --- 3) Оставляем только нужные поля, включая Handiness ---\n",
    "df = df_raw[['Subject_id', 'Name', 'Surname', 'Birthdate', 'Gender', 'Handiness']].copy()\n",
    "\n",
    "# --- 4) Преобразуем «Пол» из кириллицы в латинскую букву m/f ---\n",
    "gender_map = {'М': 'm', 'Ж': 'f'}\n",
    "df['Gender'] = df['Gender'].map(gender_map)\n",
    "\n",
    "# --- 5) Преобразуем «Handiness» в r/l ---\n",
    "# Предполагаем, что в файле пишется именно «Правша» или «Левша»\n",
    "hand_map = {'Правша': 'r', 'Левша': 'l'}\n",
    "df['Handiness'] = df['Handiness'].map(hand_map)\n",
    "\n",
    "# --- 6) Переводим «Дата Рождения» в datetime ---\n",
    "df['Birthdate'] = pd.to_datetime(df['Birthdate'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# --- 7) Считаем возраст в годах (целое число) ---\n",
    "today = datetime.today()\n",
    "def calculate_age(birth_dt):\n",
    "    if pd.isna(birth_dt):\n",
    "        return None\n",
    "    years = today.year - birth_dt.year\n",
    "    if (today.month, today.day) < (birth_dt.month, birth_dt.day):\n",
    "        years -= 1\n",
    "    return int(years)\n",
    "\n",
    "df['Age'] = df['Birthdate'].apply(calculate_age)\n",
    "\n",
    "# --- 8) Заменяем NaN в Age на 0, превращая колонку в целочисленную ---\n",
    "df['Age'] = df['Age'].fillna(0).astype(int)\n",
    "\n",
    "# --- 9) Удаляем колонку Birthdate, она больше не нужна ---\n",
    "df = df.drop(columns=['Birthdate'])\n",
    "\n",
    "# --- 10) Делаем Subject_id индексом ---\n",
    "subject_metadata = df.set_index('Subject_id')\n",
    "\n",
    "subject_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384daf6-6e25-4acb-930f-2d4a75a49244",
   "metadata": {},
   "source": [
    "### Compute and Save FFT Spectras (PSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ca51322-9376-4905-ad76-bccae1c50a59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [02:01<00:00,  3.92s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(63, 381)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mne.time_frequency import psd_array_welch\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_jobs = 72\n",
    "results_arr = []\n",
    "\n",
    "for key, (eeg, subj, trial) in tqdm(data_tuple.items()):\n",
    "    # Получаем данные (n_channels, n_times)\n",
    "    data = eeg.get_data()\n",
    "    \n",
    "    # Преобразуем в (n_epochs=1, n_channels, n_times)\n",
    "    data_reshaped = data[np.newaxis, :, :]\n",
    "\n",
    "    # FFT-параметры\n",
    "    sfreq = eeg.info['sfreq']\n",
    "    fmin, fmax = 2, 40  # Диапазон частот\n",
    "    n_fft = int(sfreq * 10)  # 10 секунд окна → частотное разрешение = 0.1 Гц\n",
    "\n",
    "    # Вычисляем спектры мощности через FFT (shape: (1, n_channels, n_freqs))\n",
    "    psds, freqs = psd_array_welch(\n",
    "        data_reshaped,\n",
    "        sfreq=sfreq,\n",
    "        fmin=fmin,\n",
    "        fmax=fmax,\n",
    "        n_fft=n_fft,\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Усредняем по времени (в данном случае один отрезок, просто берем [0])\n",
    "    power_mean = psds[0]  # (n_channels, n_freqs)\n",
    "\n",
    "    # Метаданные\n",
    "    gender    = subject_metadata.loc[subj, 'Gender']\n",
    "    handiness = subject_metadata.loc[subj, 'Handiness']\n",
    "    age       = subject_metadata.loc[subj, 'Age']\n",
    "\n",
    "    results_arr.append([power_mean, subj, trial, gender, handiness, age])\n",
    "\n",
    "# Пример формы спектра для первого результата\n",
    "results_arr[0][0].shape  # (n_channels, n_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d4c3098-d90c-493c-b7b0-3a10a4d662e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict = {}\n",
    "for i, entry in enumerate(results_arr):\n",
    "    psd, s_id, t_id, gender, handiness, age = entry\n",
    "    save_dict[f'psd_{i}'] = psd\n",
    "    save_dict[f'subject_id_{i}'] = np.array(s_id)\n",
    "    save_dict[f'trial_id_{i}'] = np.array(t_id)\n",
    "    save_dict[f'gender_{i}'] = np.array(gender, dtype='U1')\n",
    "    save_dict[f'handiness_{i}']  = np.array(handiness, dtype='U1')\n",
    "    save_dict[f'age_{i}'] = np.array(age, dtype=int)\n",
    "\n",
    "# Сохраняем в .npz\n",
    "np.savez('./Generated/Spectrums/psds_array_fft.npz', **save_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673bfaf7-5ef1-41d7-95bc-436b99965d16",
   "metadata": {},
   "source": [
    "### Visualizations (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e077e544-de24-47dd-a831-0324d9ff01a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:00<00:00,  1.94s/it]\n"
     ]
    }
   ],
   "source": [
    "from mne.time_frequency import psd_array_welch\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "results_arr = []\n",
    "\n",
    "for key, (eeg, subj, trial) in tqdm(data_tuple.items()):\n",
    "    \n",
    "    # Вычисляем PSD через MNE (дискретизация чуть меньше, чтоб было читабельно)\n",
    "    psd_mne = eeg.compute_psd(method=\"welch\", fmin=2, fmax=40, n_fft=int(eeg.info['sfreq'] * 5), verbose=False)\n",
    "    \n",
    "    # Рисуем PSD по всем каналам\n",
    "    fig_all = psd_mne.plot(average=False, show=True)\n",
    "    fig_all.suptitle(f'FFT Subject {subj} Trial {trial}', fontsize=14)\n",
    "    fig_all.savefig(f'./Generated/Figures/Spectral_Analysis/All_Experiment/FFT_S{subj}_T{trial}.png')\n",
    "    plt.close(fig_all)  # <-- Закрываем, чтобы не отображался в ноутбуке\n",
    "    \n",
    "    \n",
    "    # Рисуем усреднённый PSD\n",
    "    fig_avg = psd_mne.plot(average=True, show=True)\n",
    "    fig_avg.suptitle(f'FFT Subject {subj} Trial{trial}', fontsize=14)\n",
    "    fig_avg.savefig(f'./Generated/Figures/Spectral_Analysis/All_Experiment/FFT_S{subj}_T{trial}_Avg.png')\n",
    "    plt.close(fig_avg)  # <-- Тоже закрываем\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
